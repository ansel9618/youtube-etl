name: CI/CD for YT ETL

on: [push, pull_request]

jobs:

  build_job:
    name: build image
    runs-on: ubuntu-latest
    # Using environment named 'build' (defined in Github actions environment)
    environment:
      name: build
    # Enivornment variables pertaining to environment 'build' (defined in Github actions environment secrets)
    env:
      DATABASE_NAME: ${{secrets.DATABASE_NAME}}
      DATABASE_HOSTNAME: ${{secrets.DATABASE_HOSTNAME}}
      DATABASE_PORT: ${{secrets.DATABASE_PORT}}
      DATABASE_USERNAME: ${{secrets.DATABASE_USERNAME}}
      DATABASE_PASSWORD: ${{secrets.DATABASE_PASSWORD}}
      FERNET_KEY: ${{secrets.FERNET_KEY}}
      API_KEY: ${{secrets.API_KEY}}
      CHANNEL_ID: ${{secrets.CHANNEL_ID}}
      JOINED_DATE: ${{secrets.JOINED_DATE}}
      DOCKERHUB_USERNAME: ${{secrets.DOCKERHUB_USERNAME}}
      DOCKERHUB_REPOSITORY: ${{secrets.DOCKERHUB_REPOSITORY}}
      AIRFLOW_UID: ${{secrets.AIRFLOW_UID}}
    steps:
    # Pull git repo so you have all the files available
      - name: Pulling git repo
        uses: actions/checkout@v3
    # # Sign in to Docker Hub, build and push docker image it to Dockerhub using a Dockerfile
    #   - name: Login to Docker Hub
    #     uses: docker/login-action@v2
    #     with:
    #       username: ${{secrets.DOCKERHUB_USERNAME}}
    #       password: ${{secrets.DOCKERHUB_TOKEN}}
    #   - name: Set up Docker Buildx
    #     uses: docker/setup-buildx-action@v2
    #   - name: Build and push
    #     uses: docker/build-push-action@v4
    #     with:
    #       context: .
    #       file: ./Dockerfile
    #       push: true
    #       tags: ${{secrets.DOCKERHUB_USERNAME}}/${{secrets.DOCKERHUB_REPOSITORY}}:latest
      # Run docker compose yaml file and start airflow
      - name: Run docker compose
        uses: isbang/compose-action@v1.4.1
      # To test that DAG is working with no errors; airflow dags test <dag_id>
      # Run pytest for unit tests
      - name: Test DAG is working and run unit tests (inside scheduler docker container)
        run: |
          docker exec -t youtube-etl_airflow-scheduler_1 bash
          pytest dags/tests/ -v
        # airflow dags test yt_etl